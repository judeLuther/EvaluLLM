{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSawbcgrR2ej"
      },
      "source": [
        "### OPENAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtLo1Ur1R0dP"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "YOUR_API_KEY = \"...\"\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=YOUR_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHLOaeyjg2d"
      },
      "source": [
        "### Languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QAX-fd3zjkmy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "source_lang = \"French\"\n",
        "source_language= \"French\"\n",
        "country=\"Bolivia\"\n",
        "code=\"BO\"\n",
        "\n",
        "ethnologue_code_and_name= \"\"\"\n",
        "aroAraona\n",
        "ayoAyoreo\n",
        "brgBaure\n",
        "bvlBolivian Sign Language\n",
        "cawCallawalla\n",
        "cazCanichana\n",
        "cavCavineña\n",
        "cybCayubaba\n",
        "ayrCentral Aymara\n",
        "caoChácobo\n",
        "cajChané\n",
        "capChipaya\n",
        "caxChiquitano\n",
        "guiEastern Bolivian Guaraní\n",
        "eseEse Ejja\n",
        "gyrGuarayu\n",
        "ignIgnaciano\n",
        "iteItene\n",
        "itoItonama\n",
        "jorJorá\n",
        "lecLeco\n",
        "mpdMachinere\n",
        "mzpMovima\n",
        "qulNorth Bolivian Quechua\n",
        "pcpPacahuara\n",
        "pnkPaunaka\n",
        "psmPauserna\n",
        "puqPuquina\n",
        "reyReyesano\n",
        "sarSaraveca\n",
        "srqSirionó\n",
        "quhSouth Bolivian Quechua\n",
        "tnaTacana\n",
        "tpjTapieté\n",
        "tnoToromono\n",
        "trnTrinitario\n",
        "casTsimané\n",
        "ureUru\n",
        "mtpWeenhayek\n",
        "gnwWestern Bolivian Guaraní\n",
        "yaaYaminahua\n",
        "yuqYuqui\n",
        "yuzYuracare\n",
        "\"\"\"\n",
        "\n",
        "liste_langues = [ligne.strip() for ligne in ethnologue_code_and_name.strip().split('\\n') if ligne.strip()]\n",
        "\n",
        "print(len(liste_langues))\n",
        "\n",
        "df = pd.DataFrame({country: liste_langues})\n",
        "\n",
        "df[country] = df[country].str[3:]\n",
        "\n",
        "df.to_excel(\"langues_code.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xp335hSSuET"
      },
      "source": [
        "### Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jJRKBKusSuw5"
      },
      "outputs": [],
      "source": [
        "TWENTY_POINT_SCALE = '''\n",
        "    Here is an ideal translation in English:\n",
        "\n",
        "    ### 1. Lexical Fidelity\n",
        "    Are the words and phrases translated and then back-translated correctly?\n",
        "    *Evaluate word-for-word and idiomatic correspondences.*\n",
        "\n",
        "    **Rating Scale:**\n",
        "\n",
        "    * **0** = Frequent mistranslations / **1** = Several significant errors / **2** = A few acceptable deviations / **3** = Good overall correspondence / **4** = Very high lexical fidelity\n",
        "\n",
        "    ### 2. Syntactic Structure\n",
        "    Are the word order, grammar, and punctuation consistent with the original text?\n",
        "\n",
        "    **Rating Scale:**\n",
        "\n",
        "    * **0** = Disorganized / **1** = Major errors / **2** = Acceptable but awkward / **3** = Fluent with minor errors / **4** = Very well-structured\n",
        "\n",
        "    ### 3. Overall Meaning Conveyance\n",
        "    Is the core message understood, even if some words are not identical?\n",
        "\n",
        "    **Rating Scale:**\n",
        "\n",
        "    * **0** = Incomprehensible / **1** = Numerous ambiguities / **2** = General meaning preserved but with some loss / **3** = Well conveyed / **4** = Message perfectly clear\n",
        "\n",
        "    ### 4. Tone and Register\n",
        "    Is the tone (e.g., formal/informal, empathetic, neutral) preserved?\n",
        "\n",
        "    **Rating Scale:**\n",
        "\n",
        "    * **0** = Inconsistent / **1** = Major discrepancies / **2** = Register is shaky but acceptable / **3** = Tone is well-respected / **4** = Register is accurate and natural\n",
        "\n",
        "    ### 5. Natural Fluency\n",
        "    Does the back-translated version sound natural and \"human\"?\n",
        "\n",
        "    **Rating Scale:**\n",
        "\n",
        "    * **0** = Broken or robotic language / **1** = Difficult to follow / **2** = Readable but awkward / **3** = Relatively fluent / **4** = Very fluent and natural\n",
        "\n",
        "    Final Score: Add the 5 scores for a total out of 20.\n",
        "\n",
        "    Possible Interpretation:\n",
        "    [17–20]: Excellent language proficiency\n",
        "    [14–16]: Good proficiency, suitable for professional use\n",
        "    [10–13]: Average, some weaknesses but understandable\n",
        "    [6–9]: Weak, risky translation\n",
        "    [0–5]: Very weak, unfit for real use\n",
        "    '''\n",
        "\n",
        "EXPECTED_FORMAT = \"\"\"\n",
        "    {\n",
        "    \"total_Score\": \"[sum_of_all_scores]\",\n",
        "    \"scores\": {\n",
        "        \"1. Lexical Fidelity\": numerical_score_for_lexical_fidelity,\n",
        "        \"2. Syntactic Structure\": numerical_score_for_syntactic_structure,\n",
        "        \"3. Overall Meaning Conveyance\": numerical_score_for_overall_meaning,\n",
        "        \"4. Tone and Register\": numerical_score_for_tone_and_register,\n",
        "        \"5. Natural Fluency\": numerical_score_for_natural_fluency\n",
        "    }\n",
        "    }\n",
        "\n",
        "    Justification: [brief justification for each score here]\n",
        "    \"\"\"\n",
        "\n",
        "system_prompt = '''\n",
        "You are a translator specialized in low-resource languages.\n",
        "Your primary task is to provide translations even for languages or phrases where full or official data may be limited.\n",
        "Even if you do not know the exact or complete translation, you must always attempt to provide the best possible approximation based on context, linguistic patterns, and related languages.\n",
        "Never respond with \"I don't know\"—always try.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh43QEZjS793"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "vGY3HsniS9Ej"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Compares the original and back-translated text, providing a score and justification.\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "This file defines a generic translation function using the OpenAI API.\n",
        "\"\"\"\n",
        "def generate_translation(paragraph, target_lang, country, model):\n",
        "    prompt = f'''Without making comments or giving explanations,\n",
        "    translate the following text into authentic {target_lang} spoken in {country}.\n",
        "    Whatever the result, try :\n",
        "\n",
        "    {paragraph}\n",
        "    '''\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "def generate_back_translation(translation, target_lang, source_lang, country, model):\n",
        "    prompt = f'''The text below is in authentic {target_lang}, a language spoken in {country}.\n",
        "    Without making any comments or explanations, translate it into {source_lang} :\n",
        "\n",
        "    {translation}\n",
        "    '''\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def llm_analysis(original, back_translated, source_lang, model=\"google/gemini-2.5-pro\"):\n",
        "    prompt_system = f\"\"\" **Context:** You are going to evaluate the quality of a back-translation into {source_lang} of an original text that is also in {source_lang}.\n",
        "                The process is as follows: An original text was written in {source_lang}. It was translated into a foreign language (you will not know which one).\n",
        "                This foreign translation was then translated back into {source_lang}, resulting in the back-translated text.\n",
        "\n",
        "                **Objective:** Compare the original text with the back-translated text.\n",
        "\n",
        "                **Task:** Assign a score out of 20 based on my linguistic evaluation rubric, provided as :\n",
        "\n",
        "                {TWENTY_POINT_SCALE}\n",
        "\n",
        "                Expected Response Format:\n",
        "\n",
        "                {EXPECTED_FORMAT}\n",
        "\n",
        "\n",
        "                \"\"\"\n",
        "\n",
        "    prompt_user = f\"\"\"\n",
        "\n",
        "        Here are the texts to compare:\n",
        "\n",
        "        **Original Text:**\n",
        "\n",
        "        {original}\n",
        "\n",
        "        **Back-translated Text:**\n",
        "\n",
        "        {back_translated}\n",
        "\n",
        "        **Additional Instructions:**\n",
        "        * Do not make assumptions about the intermediate language.\n",
        "        * Base your evaluation solely on the comparison of the two texts.\n",
        "        * If discrepancies or errors hinder comprehension or alter the meaning, penalize according to the rubric.\n",
        "        * You must justify your score.\n",
        "\n",
        "        Expected Response Format:\n",
        "\n",
        "        {EXPECTED_FORMAT}\n",
        "\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt_system},\n",
        "                  {\"role\": \"user\", \"content\": prompt_user}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "def extract_score_and_justification(response_text):\n",
        "    score = -1\n",
        "    justification = \"Missing\"\n",
        "\n",
        "    note_match = re.search(r'\"scores\"\\s*:\\s*(\\{(?:.|\\n)*?\\})', response_text)\n",
        "    if note_match:\n",
        "        note_block = note_match.group(1)\n",
        "        pairs = re.findall(r'\"(\\d+)\\.\\s*[^\"]*\"\\s*:\\s*(\\d+(?:\\.\\d+)?)', note_block)\n",
        "        criteria = {num: float(val) for num, val in pairs}\n",
        "        if len(criteria) == 5:\n",
        "            score = sum(criteria.values())\n",
        "\n",
        "    just_match = re.search(r\"Justification\\s*:\\s*(.+)\", response_text, re.DOTALL)\n",
        "    if just_match:\n",
        "        justification = just_match.group(1).strip()\n",
        "\n",
        "    return score, justification\n",
        "\n",
        "def confirm_translation(country, translation, target_lang):\n",
        "    pred1 = \"openai/GPT-4-turbo\"\n",
        "    pred2 = \"google/gemini-2.5-pro\"\n",
        "\n",
        "    sys_prompt = f\"\"\"\n",
        "    You are a language specialist. Your task is to determine whether a given text is written in {target_lang} as used in {country}.\n",
        "    Answer with exactly one word on a single line, either:\n",
        "\n",
        "    Yes\n",
        "    or\n",
        "    No\n",
        "    \"\"\"\n",
        "\n",
        "    p = f\"\"\"Is the text below in {target_lang}?\n",
        "\n",
        "    {translation}\n",
        "    \"\"\"\n",
        "\n",
        "    # First model\n",
        "    response = client.chat.completions.create(\n",
        "        model=pred1,\n",
        "        messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
        "                  {\"role\": \"user\", \"content\": p}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    resp1 = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Second model\n",
        "    response = client.chat.completions.create(\n",
        "        model=pred2,\n",
        "        messages=[{\"role\": \"system\", \"content\": sys_prompt},\n",
        "                  {\"role\": \"user\", \"content\": p}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    resp2 = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Normalizing responses to handle accidental case differences/spaces\n",
        "    resp1 = resp1.lower()\n",
        "    resp2 = resp2.lower()\n",
        "\n",
        "    if resp1 == \"yes\" and resp2 == \"yes\":\n",
        "        confidence = 1\n",
        "    else:\n",
        "        confidence = 0\n",
        "\n",
        "    return confidence\n",
        "\n",
        "def process_row(paragraph, source_lang, target_lang, country, models):\n",
        "    \"\"\"\n",
        "    models: liste de noms de modèles (str)\n",
        "    Retourne: liste de tuples (nom_model, score)\n",
        "    \"\"\"\n",
        "    if len(paragraph.strip()) < 10:\n",
        "        return [(model, \"Content too short\") for model in models]\n",
        "\n",
        "    results = []\n",
        "    for model in models:\n",
        "        try:\n",
        "            translation = generate_translation(paragraph, target_lang, country, model)\n",
        "            back_translation = generate_back_translation(translation, target_lang, source_lang, country, model)\n",
        "\n",
        "            if not translation.strip() or not back_translation.strip():\n",
        "                results.append((model, -1))\n",
        "                continue\n",
        "\n",
        "            evaluation = llm_analysis(paragraph, back_translation, source_lang)\n",
        "            score, _ = extract_score_and_justification(evaluation)\n",
        "\n",
        "            confidence = confirm_translation(country, translation, target_lang)\n",
        "\n",
        "            results.append((model, score, confidence))\n",
        "\n",
        "        except Exception:\n",
        "            results.append((model, -1, -1))\n",
        "\n",
        "    return results\n",
        "\n",
        "def process_file(source_lang, country, paragraph, selected_models, df):\n",
        "    country_dir = os.path.join(\".\", country)\n",
        "    os.makedirs(country_dir, exist_ok=True)\n",
        "\n",
        "    total_tasks = len(df) * len(selected_models)\n",
        "\n",
        "    with tqdm(total=total_tasks, desc=f\"Processing all models for {country}\") as pbar:\n",
        "        for _, row in df.iterrows():\n",
        "            target_lang = row[country]\n",
        "            lang_dir = os.path.join(country_dir, target_lang)\n",
        "            os.makedirs(lang_dir, exist_ok=True)\n",
        "\n",
        "            for model in selected_models:\n",
        "                json_path = os.path.join(lang_dir, f\"{model.replace('/', '_')}.json\")\n",
        "\n",
        "                if os.path.exists(json_path):\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                results = process_row(paragraph, source_lang, target_lang, country, [model])\n",
        "                for m, score, confidence in results:\n",
        "                    model_info = selected_models[m]\n",
        "                    task_types = [\n",
        "                        {\n",
        "                            \"name\": \"translation\",\n",
        "                            \"type\": \"translation\",\n",
        "                            \"score\": score,\n",
        "                            \"source_languages\": [source_lang],\n",
        "                            \"domains\": [\"general\"],\n",
        "                            \"modalities\": [\"text\"]\n",
        "                        },\n",
        "                        {\n",
        "                            \"name\": \"other\",\n",
        "                            \"type\": \"other\",\n",
        "                            \"score\": 0.0,\n",
        "                            \"source_languages\": [source_lang],\n",
        "                            \"domains\": [\"general\"],\n",
        "                            \"modalities\": [\"text\"]\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "                    json_data = {\n",
        "                        \"model_name\": m,\n",
        "                        \"max_tokens\": model_info[\"max_tokens\"],\n",
        "                        \"embed_dim\": model_info[\"embed_dim\"],\n",
        "                        \"n_parameters\": model_info[\"n_parameters\"],\n",
        "                        \"zero_shot_percentage\": 100,\n",
        "                        \"confidence\": confidence,\n",
        "                        \"reference\": f\"https://openrouter.ai/{m}\",\n",
        "                        \"task_type\": task_types\n",
        "                    }\n",
        "\n",
        "                    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        json.dump(json_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "                    pbar.update(1)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsdIXYn2TdOF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing all models for Bolivia: 100%|██████████| 43/43 [1:19:47<00:00, 111.34s/it]\n"
          ]
        }
      ],
      "source": [
        "# Write the text you want to evaluate here.\n",
        "paragraph='''Conversation 1\n",
        "Villageois :\n",
        "Allô, bonjour je suis dans la forêt pour chasser le gibier, c’est la période de l’ouverture de la chasse dans mon pays. Je vous appelle parce que mon frère qui est avec moi en forêt pour la chasse a été mordu par un serpent. Je ne sais pas quoi faire. J’ai besoin de votre assistance s’il vous plaît.\n",
        "Assistant :\n",
        "Allô, bonjour je suis une assistante vocale qui va te guider pour te permettre d’avoir des informations pertinentes et t’accompagner tout au long de la prise en charge de ton frère mordu par un serpent. Dis-moi depuis environ combien de temps ton frère a été mordu ?\n",
        "Villageois :\n",
        "Aidez-moi s’il vous plait, j’ai peur pour mon frère.\n",
        "Assistant :\n",
        "Je comprends très bien votre situation et l’angoisse que cela peut engendrer, reste calme et lucide, surtout ne panique pas, je vais te poser une série de questions qui me permettront de te diriger vers le centre de santé le plus proche. Peux-tu répondre à mes questions ?\n",
        "Villageois :\n",
        "Oui, vas-y\n",
        "Assistant :\n",
        "Dis-moi depuis environ combien de temps ton frère a été mordu ?\n",
        "Villageois :\n",
        "Depuis environ 5 minutes. Il a été mordu au niveau de la cheville du pied gauche, j’ai alors attaché assez fort un morceau de pagne à peu près autour de son genou gauche pour que le venin ne circule pas.\n",
        "Assistant :\n",
        "A part l’astuce du pagne pour éviter le venin de monter, as-tu essayé une autre astuce ?\n",
        "Villageois :\n",
        "Non, je ne sais pas faire de premiers secours dans ce genre de problème.\n",
        "Assistant :\n",
        "C’est très bien ce que tu as fait. Ton frère ressent-il de la fatigue générale ?\n",
        "Villageois :\n",
        "Il arrive encore à marcher.\n",
        "Assistant :\n",
        "Ton frère ressent-il de la douleur ?\n",
        "Villageois :\n",
        "Oui, il dit que la douleur n’est pas trop intense.\n",
        "Assistant :\n",
        "Connais-tu quelle espèce de serpent a mordu ton frère ?\n",
        "Villageois :\n",
        "Non, l’incident s’est rapidement déroulé, le serpent est entré dans la brousse, je n’ai eu le temps de l’identifier.\n",
        "Assistant :\n",
        "Etes-vous proche du village ?\n",
        "Villageois :\n",
        "Oui, le nom du village est Vo\n",
        "Assistant :\n",
        "Voici le numéro du centre de santé le plus proche, c’est le 01 04 09 appeler ce centre pour avoir les informations fiables. Ils sont formés et ont les moyens de t’envoyer une ambulance dans votre village.\n",
        "Villageois :\n",
        "Répète le numéro pour que je prenne note\n",
        "Assistant :\n",
        "As-tu des questions ?\n",
        "Villageois :\n",
        "Non\n",
        "Assistant :\n",
        "N’hésite surtout pas à me contacter à tout moment si tu as d’autres questions.\n",
        "'''\n",
        "\n",
        "# Add the models you want to evaluate here. You can find their IDs at https://openrouter.ai\n",
        "models_to_evaluate = {\n",
        "    ##Openai\n",
        "  #   \"openai/gpt-5-chat\": {\n",
        "  #       \"max_tokens\": 400000,\n",
        "  #       \"embed_dim\": 18432,\n",
        "  #       \"n_parameters\": 3e11\n",
        "  #   },\n",
        "  #   \"openai/gpt-5\": {\n",
        "  #       \"max_tokens\": 400000,\n",
        "  #       \"embed_dim\": 18432,\n",
        "  #       \"n_parameters\": 3e11\n",
        "  #   },\n",
        "  #   \"openai/gpt-5-mini\": {\n",
        "  #       \"max_tokens\": 400000,\n",
        "  #       \"embed_dim\": 16000,\n",
        "  #       \"n_parameters\": 5e10\n",
        "  #   },\n",
        "  #   \"openai/gpt-5-nano\": {\n",
        "  #       \"max_tokens\": 400000,\n",
        "  #       \"embed_dim\":  8000,\n",
        "  #       \"n_parameters\": 2e10\n",
        "  #   },\n",
        "  #   \"openai/gpt-oss-120b\": {\n",
        "  #       \"max_tokens\": 131072,\n",
        "  #       \"embed_dim\": 16000,\n",
        "  #       \"n_parameters\": 1.17e11\n",
        "  #   },\n",
        "  #   \"openai/gpt-oss-20b\": {\n",
        "  #       \"max_tokens\": 131072,\n",
        "  #       \"embed_dim\": 8000,\n",
        "  #       \"n_parameters\": 2.1e10\n",
        "  #   },\n",
        "  #   \"openai/gpt-4-turbo\": {\n",
        "  #       \"max_tokens\": 128000,\n",
        "  #       \"embed_dim\": 15360,\n",
        "  #       \"n_parameters\": 1.76e12\n",
        "  #   },\n",
        "  #   \"openai/o3-pro\": {\n",
        "  #       \"max_tokens\": 200000,\n",
        "  #       \"embed_dim\": 16000,\n",
        "  #       \"n_parameters\": 1.43e11\n",
        "  #   },\n",
        "  #   \"openai/o4-mini-high\": {\n",
        "  #       \"max_tokens\": 200000,\n",
        "  #       \"embed_dim\": 12000,\n",
        "  #       \"n_parameters\": 1e10\n",
        "  #   },\n",
        "    \"openai/o3\": {\n",
        "        \"max_tokens\":  200000,\n",
        "        \"embed_dim\": 16000,\n",
        "        \"n_parameters\": 1.43e11\n",
        "    },\n",
        "    # \"openai/o4-mini\": {\n",
        "    #     \"max_tokens\": 200000,\n",
        "    #     \"embed_dim\": 12000,\n",
        "    #     \"n_parameters\": 1e10\n",
        "    # },\n",
        "  #   \"openai/gpt-4.1\": {\n",
        "  #       \"max_tokens\": 1047576,\n",
        "  #       \"embed_dim\": 16000,\n",
        "  #       \"n_parameters\": 1.8e12\n",
        "  #   },\n",
        "  #   \"openai/gpt-4.1-mini\": {\n",
        "  #       \"max_tokens\": 1047576,\n",
        "  #       \"embed_dim\": 12000,\n",
        "  #       \"n_parameters\": 8e9\n",
        "  #   },\n",
        "  #   ##Gemini\n",
        "  #   \"google/gemini-2.5-flash-lite\": {\n",
        "  #   \"max_tokens\": 1048576,\n",
        "  #   \"embed_dim\": 6144,\n",
        "  #   \"n_parameters\": 6e9\n",
        "  # },\n",
        "  # \"google/gemma-3n-e2b-it:free\": {\n",
        "  #   \"max_tokens\": 8192,\n",
        "  #   \"embed_dim\": 4096,\n",
        "  #   \"n_parameters\": 5.44e9\n",
        "  # },\n",
        "  # \"google/gemini-2.5-flash\": {\n",
        "  #   \"max_tokens\": 1048576,\n",
        "  #   \"embed_dim\": 8192,\n",
        "  #   \"n_parameters\": 2e10\n",
        "  # },\n",
        "  # \"google/gemini-2.5-pro\": {\n",
        "  #   \"max_tokens\": 1048576,\n",
        "  #   \"embed_dim\": 12288,\n",
        "  #   \"n_parameters\": 5e10\n",
        "  # },\n",
        "  # \"google/gemma-2b-it\": {\n",
        "  #   \"max_tokens\": 8192,\n",
        "  #   \"embed_dim\": 4096,\n",
        "  #   \"n_parameters\": 2.51e9\n",
        "  # },\n",
        "  # \"google/gemma-3n-e4b-it\": {\n",
        "  #   \"max_tokens\": 32768,\n",
        "  #   \"embed_dim\": 5120,\n",
        "  #   \"n_parameters\": 7.85e9\n",
        "  # },\n",
        "  # \"google/gemma-2-27b-it\": {\n",
        "  #   \"max_tokens\": 8192,\n",
        "  #   \"embed_dim\": 12288,\n",
        "  #   \"n_parameters\": 27.2e9\n",
        "  # },\n",
        "  # \"google/gemini-2.0-flash-lite-001\": {\n",
        "  #   \"max_tokens\": 200000,\n",
        "  #   \"embed_dim\": 6144,\n",
        "  #   \"n_parameters\": 6e9\n",
        "  # },\n",
        "  # \"google/gemini-2.0-flash-001\": {\n",
        "  #   \"max_tokens\": 1048576,\n",
        "  #   \"embed_dim\": 8192,\n",
        "  #   \"n_parameters\": 20e9\n",
        "  # },\n",
        "  # \"google/gemini-flash-1.5-8b\": {\n",
        "  #   \"max_tokens\": 200000,\n",
        "  #   \"embed_dim\": 8192,\n",
        "  #   \"n_parameters\": 8e9\n",
        "  # },\n",
        "  # \"google/gemini-flash-1.5\": {\n",
        "  #   \"max_tokens\": 1000000,\n",
        "  #   \"embed_dim\": 6144,\n",
        "  #   \"n_parameters\": 6e9\n",
        "  # },\n",
        "  # \"google/gemini-pro-1.5\": {\n",
        "  #   \"max_tokens\": 2000000,\n",
        "  #   \"embed_dim\": 12288,\n",
        "  #   \"n_parameters\": 5e10\n",
        "  # },\n",
        "  # \"google/gemma-7b-it\": {\n",
        "  #   \"max_tokens\": 8192,\n",
        "  #   \"embed_dim\": 8192,\n",
        "  #   \"n_parameters\": 8.54e9\n",
        "  # },\n",
        "  # \"google/gemma-3-12b-it\": {\n",
        "  #   \"max_tokens\": 131072,\n",
        "  #   \"embed_dim\": 8192,\n",
        "  #   \"n_parameters\": 12.2e9\n",
        "  # },\n",
        "  #\n",
        "  #   ##mistralai\n",
        "#   \"mistralai/mistral-medium-3.1\": {\n",
        "#   \"max_tokens\": 262144,\n",
        "#   \"embed_dim\": 5120,\n",
        "#   \"n_parameters\": 12.2e9\n",
        "# },\n",
        "#   \"mistralai/mistral-small-3.2-24b-instruct\": {\n",
        "#   \"max_tokens\": 128000,\n",
        "#   \"embed_dim\": 8192,\n",
        "#   \"n_parameters\": 24e9\n",
        "# },\n",
        "# \"mistralai/magistral-small-2506\": {\n",
        "#   \"max_tokens\": 40000,\n",
        "#   \"embed_dim\": 8192,\n",
        "#   \"n_parameters\": 24e9\n",
        "# },\n",
        "# \"mistralai/magistral-medium-2506\": {\n",
        "#   \"max_tokens\": 40960,\n",
        "#   \"embed_dim\": 12288,\n",
        "#   \"n_parameters\": 40e9\n",
        "# },\n",
        "# \"mistralai/mistral-medium-3\": {\n",
        "#   \"max_tokens\": 131072 ,\n",
        "#   \"embed_dim\": 12288,\n",
        "#   \"n_parameters\": 40e9\n",
        "# },\n",
        "# \"mistralai/mistral-small-3.1-24b-instruct\": {\n",
        "#   \"max_tokens\": 131072,\n",
        "#   \"embed_dim\": 8192,       \n",
        "#   \"n_parameters\": 24e9\n",
        "# },\n",
        "# \"mistralai/mistral-saba\": {\n",
        "#   \"max_tokens\": 32768,\n",
        "#   \"embed_dim\": 8192,         \n",
        "#   \"n_parameters\": 24e9,\n",
        "# }\n",
        "}\n",
        "\n",
        "process_file(source_lang=source_lang, country=country,  paragraph=paragraph, selected_models=models_to_evaluate, df=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLybEX0WfoOq",
        "outputId": "456ed16f-6eb1-4790-b04f-e163c2782855"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import json\n",
        "\n",
        "# root_folder = \"Nigeria\"\n",
        "\n",
        "# for subdir, _, files in os.walk(root_folder):\n",
        "#     for file in files:\n",
        "#         if file.endswith(\".json\"):\n",
        "#             file_path = os.path.join(subdir, file)\n",
        "#             try:\n",
        "#                 with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#                     data = json.load(f)\n",
        "\n",
        "#                 data[\"zero_shot_percentage\"] = 100\n",
        "\n",
        "#                 with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#                     json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "#                 print(f\"Updated: {file_path}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error processing {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concatenate all files to generate JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC6VOg45JCqb"
      },
      "outputs": [],
      "source": [
        "%run \"C:\\Users\\Users\\Documents\\BENCHMARK_RESULTS\\create_dataset.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVie1afgzOrN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clés principales : dict_keys(['benchmarks'])\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = \"https://huggingface.co/datasets/lojl/llms_low_resource_benchmark_2025/resolve/main/benchmarks.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    ALL_BENCHMARKS_DATA = json.loads(response.text)\n",
        "    print(\"Clés principales :\", ALL_BENCHMARKS_DATA.keys())\n",
        "else:\n",
        "    ALL_BENCHMARKS_DATA = {}\n",
        "    print(\"Erreur :\", response.status_code)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
